{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "path = './dataset'\n",
    "dataset = []\n",
    "\n",
    "directories = os.listdir(path)\n",
    "for dir_name in directories:\n",
    "    path_file = path + '/' + dir_name\n",
    "    files = os.listdir(path_file)\n",
    "    for file_name in files:\n",
    "        path_to_open = path_file + '/' + file_name\n",
    "        with open(path_to_open, 'r') as f:\n",
    "            tweet_info = {}\n",
    "            read_file = json.loads(f.read())\n",
    "            tweet_info['trending_topic'] = dir_name\n",
    "            tweet_info['tweet'] = read_file['text']\n",
    "            dataset.append(tweet_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset):\n",
    "    dataset.to_csv('twitter_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2458, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_tweets = pd.DataFrame(dataset)\n",
    "df_tweets_train = df_tweets.copy()\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#PesonaAngklungFestival    2458\n",
       "Name: trending_topic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['trending_topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kontrak Ramsey bakal abis di akhir musim ini. Ayo tim pencari pemain gratisan siap2 rebutan. Kira2 tim manakah yg beruntung?? :)\\n.\\n#ramsey  #arsenal  #free  #transfer  #kontrak  #gratis  #like4like  #comment4comment  #likeme  #vacation  #PressconMissWorld2018  #PesonaAngklungFestival   pic.twitter.com/wB6G6wf6nB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['tweet'].iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "https://github.com/riochr17/Named-Entity-Tagger-ID\n",
    "<br>\n",
    "https://github.com/lilia-simeonova/preprocessing-tweets\n",
    "<br>\n",
    "http://iopscience.iop.org/article/10.1088/1742-6596/801/1/012072/pdf\n",
    "<br>\n",
    "http://taufiksutanto.blogspot.com/2018/01/tokenization-dalam-bahasa-inggris.html\n",
    "<br>\n",
    "http://www.yasirblog.com/2017/05/normalisasi-data-text-text.html\n",
    "<br>\n",
    "http://norvig.com/spell-correct.html\n",
    "<br>\n",
    "https://github.com/sastrawi/nlp-bahasa-indonesia\n",
    "<br>\n",
    "https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_translator import Translator\n",
    "import enchant\n",
    "\n",
    "def translate(text):\n",
    "    counter = 1;\n",
    "    checker = enchant.Dict(\"en_US\")\n",
    "    split_text = text.split(' ')\n",
    "    words = []\n",
    "    translator = Translator()\n",
    "    for word in split_text:\n",
    "        if word != '':\n",
    "            if checker.check(word) and word != 'twitter':\n",
    "                translated_word = translator.translate(text=word, dest='id', src='en').text \n",
    "                words.append(translated_word)\n",
    "                if counter > 10:\n",
    "                    delay_request(5,7)\n",
    "                    counter = 1\n",
    "            else:\n",
    "                words.append(word.replace(' ',''))\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import random\n",
    "\n",
    "def delay_request(lower, upper):\n",
    "    print(random.uniform(lower, upper))\n",
    "    sleep(random.uniform(lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_url(text):\n",
    "    return re.sub(r'http\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    return re.sub(r'(^|\\s)(:D|:\\/|:\\)+|;\\)|:-\\))(?=\\s|[^[:alnum:]+-]|$)', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def spell_checker(text):\n",
    "    words = text.split(' ')\n",
    "    with open('spellchecker.json') as file_opened:\n",
    "        text = file_opened.read()\n",
    "    word_checker = json.loads(text)\n",
    "    for idx in range(len(words)):\n",
    "        if words[idx] in word_checker:\n",
    "            words[idx] = word_checker[words[idx]]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitue_character(text):\n",
    "    new_text = text.encode('ascii',errors='ignore').decode('utf-8', 'ignore')\n",
    "    new_text = new_text.replace('\\n', ' ')\n",
    "    new_text = new_text.replace('?', ' ')\n",
    "    new_text = new_text.replace('\"', '')\n",
    "    new_text = new_text.replace(\"'\", '')\n",
    "    new_text = re.sub(r'[.,\\/!$%\\^&\\*;:{}=\\`~()]', ' ', new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwilingga(text):\n",
    "    match = re.match(r'\\w*(?=2(nya)?)', text)\n",
    "    if match is not None:\n",
    "        words = text.split(' ')\n",
    "        for idx in range(len(words)):\n",
    "            match_word = re.match(r'\\w*(?=2(nya)?)', words[idx])\n",
    "            if match_word is not None:\n",
    "                words[idx] = words[idx].replace('2', '-' + match_word.group())\n",
    "        return \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_code_word(text):\n",
    "    match = re.search(r'(?:[\\d]+[\\w]|[\\w]+[\\d])[\\w\\d]*', text)\n",
    "    if match is not None:\n",
    "        words = text.split(' ')\n",
    "        for idx in range(len(words)):\n",
    "            match_word = re.match(r'(?:[\\d]+[\\w]|[\\w]+[\\d])[\\w\\d]*', words[idx])\n",
    "            match_hastag = re.match(r'(#[\\w\\d]*)', words[idx])\n",
    "            if match_word is not None and match_hastag is None:\n",
    "                words[idx] = ''\n",
    "        return \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_fixing(text):\n",
    "    match = re.search(r'\\b[bkmpst][bcdfghjklmnpqrstvwxyz]', text)\n",
    "    words = text.split(' ')\n",
    "    if match is not None:\n",
    "        for idx in range(len(words)):\n",
    "            match_word = re.search(r'\\b[bkmpst][bcdfghjklmnpqrstvwxyz]', words[idx])\n",
    "            if match_word is not None:\n",
    "                words[idx] = words[idx][0] + 'e' + words[idx][1:]\n",
    "    match3 = re.search(r'\\b[p][bcdefghjklmnpqstvwxyz]', text)\n",
    "    if match3 is not None:\n",
    "        for idx in range(len(words)):\n",
    "            match_word = re.search(r'\\b[p][bcdfghjklmnpqstvwxyz]', words[idx])\n",
    "            if match_word is not None:\n",
    "                words[idx] = words[idx][0] + 'i' + words[idx][1:]\n",
    "    match2 = re.search(r'\\b[d][bcdefghjklmnpqrstvwxyz]', text)\n",
    "    if match2 is not None:\n",
    "        for idx in range(len(words)):\n",
    "            match_word = re.search(r'\\b[d][bcdfghjklmnpqrstvwxyz]', words[idx])\n",
    "            if match_word is not None:\n",
    "                words[idx] = words[idx][0] + 'i' + words[idx][1:]\n",
    "    return \" \".join(words) if match is not None or match2 is not None or match3 is not None else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_word(text):\n",
    "    match = re.match(r'(?!ke)\\d*\\b', text)\n",
    "    number_dict = {\n",
    "        '1': 'satu',\n",
    "        '2': 'dua',\n",
    "        '3': 'tiga',\n",
    "        '4': 'empat',\n",
    "        '5': 'lima',\n",
    "        '6': 'enam',\n",
    "        '7': 'tujuh',\n",
    "        '8': 'delapan',\n",
    "        '9': 'sembilan'\n",
    "    }\n",
    "    if match is not None:\n",
    "        words = text.split(' ')\n",
    "        for idx in range(len(words)):\n",
    "            match_word = re.match(r'(?!ke)\\d*\\b', words[idx])\n",
    "            if match_word is not None:\n",
    "                words[idx] = words[idx].replace('2', '-' + match_word.group())\n",
    "        return \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mention(text):\n",
    "    return re.sub(r'@[\\w\\d_]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_to_many_character(text):\n",
    "    list_of_char = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    list_of_vocal = ['a', 'i', 'u', 'e', 'o']\n",
    "    new_text = text\n",
    "    for idx in range(len(list_of_vocal)):\n",
    "        for jdx in range(idx, len(list_of_vocal)):\n",
    "            pattern = r'\\b' + list_of_vocal[idx] + list_of_vocal[jdx] + r'\\b'\n",
    "            pattern_2 = r'\\b' + list_of_vocal[jdx] + list_of_vocal[idx] + r'\\b'\n",
    "            pattern_3 = r'\\b[bcdfghjklmnpqrstvwxyz][bcdfghjklmnpqrstvwxyz]\\b'\n",
    "            new_text = re.sub(pattern, '', new_text)\n",
    "            new_text = re.sub(pattern_2, '', new_text)\n",
    "            new_text = re.sub(pattern_3, '', new_text)\n",
    "    for character in list_of_char:\n",
    "        pattern = character + r'{3,}'\n",
    "        pattern_2 = character + r'{2,}\\b'\n",
    "        new_text = re.sub(pattern, character, new_text)\n",
    "        new_text = re.sub(pattern_2, character, new_text)\n",
    "    new_text = re.sub(r'(wk){2,}', '', new_text)\n",
    "    new_text = re.sub(r'(ha){2,}', '', new_text)\n",
    "    new_text = re.sub(r'(he){2,}', '', new_text)\n",
    "    new_text = re.sub(r'(hi){2,}', '', new_text)\n",
    "    new_text = re.sub(r'(bla){2,}', '', new_text)\n",
    "    new_text = re.sub(r'\\b[a-z]\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(kw)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(ha)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(he)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(bla)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(hi)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(co)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(id)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(com)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(org)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(net)\\b', '', new_text)\n",
    "    new_text = re.sub(r'\\b(gov)\\b', '', new_text)\n",
    "    new_text = remove_mention(new_text)\n",
    "    new_text = remove_code_word(new_text)\n",
    "    new_text = dwilingga(new_text)\n",
    "    new_text = rank_word(new_text)\n",
    "    new_text = prefix_fixing(new_text)\n",
    "    new_text = re.sub(r' {2,}', ' ', new_text)\n",
    "    new_text = re.sub(r'twitter', '', new_text)\n",
    "    new_text = re.sub(r'tewitter', '', new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "def remove_stop_words(sentence):\n",
    "    factory = StopWordRemoverFactory().create_stop_word_remover()\n",
    "    return factory.remove(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "def stemming(sentence):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    return stemmer.stem(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    new_text = substitue_character(text)\n",
    "    new_text = convert_text_to_lowercase(new_text)\n",
    "    new_text = remove_url(new_text)\n",
    "    new_text = remove_emoji(new_text)\n",
    "    new_text = cut_to_many_character(new_text)\n",
    "#     new_text = translate(new_text)\n",
    "    new_text = remove_stop_words(new_text)\n",
    "    new_text = spell_checker(new_text)\n",
    "    new_text = stemming(new_text)\n",
    "    new_text = new_text.replace('#', '')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_train['tweet'] = df_tweets_train['tweet'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_list(tweets):\n",
    "    word_frequencies = []\n",
    "    word_dict = []\n",
    "    for tweet in tweets:\n",
    "        words_in_sentence = tweet.split(' ')\n",
    "        for word in words_in_sentence:\n",
    "            if word in word_dict:\n",
    "                word_frequencies[word_dict.index(word)] += 1\n",
    "            else:\n",
    "                word_frequencies.append(1)\n",
    "                word_dict.append(word)\n",
    "    return word_dict, word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_word_list(word_dict, word_frequencies, treshold=2):\n",
    "    new_word_frequencies = word_frequencies.copy()\n",
    "    new_word_dict = word_dict.copy()\n",
    "    idx = 0\n",
    "    while idx < len(new_word_frequencies):\n",
    "        if new_word_frequencies[idx] < treshold:\n",
    "            new_word_dict.pop(idx)\n",
    "            new_word_frequencies.pop(idx)\n",
    "        else:\n",
    "            idx += 1\n",
    "    return new_word_dict, new_word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_frequencies_list_all(tweets):\n",
    "    graph = []\n",
    "    graph_idx = 0\n",
    "    for tweet in tweets:\n",
    "        words_in_sentence = tweet.split(' ')\n",
    "        prev_idx = -1\n",
    "        idx_now = 0\n",
    "        for word in words_in_sentence:\n",
    "            if word != '':\n",
    "                is_not_in_graph = True\n",
    "                for idx_graph in range(len(graph)):\n",
    "                    if graph[idx_graph]['word'] == word:\n",
    "                        graph[idx_graph]['counter'] += 1\n",
    "                        is_not_in_graph = False\n",
    "                        idx_graph_representation = idx_graph\n",
    "                        break\n",
    "                if is_not_in_graph:\n",
    "                    node = {\n",
    "                        'idx': graph_idx,\n",
    "                        'word': word,\n",
    "                        'counter': 1,\n",
    "                        'next_neighbours': [],\n",
    "                        'prev_neighbours': []\n",
    "                    }\n",
    "                    if prev_idx != -1:\n",
    "                        node['prev_neighbours'].append(prev_idx)\n",
    "                        if graph_idx not in graph[prev_idx]['next_neighbours'] and graph_idx != prev_idx:\n",
    "                            graph[prev_idx]['next_neighbours'].append(graph_idx)\n",
    "                    prev_idx = graph_idx\n",
    "                    graph_idx += 1\n",
    "                    graph.append(node)\n",
    "                else:\n",
    "                    if prev_idx != -1:\n",
    "                        if prev_idx not in graph[idx_graph_representation]['prev_neighbours'] and idx_graph_representation != prev_idx:\n",
    "                            graph[idx_graph_representation]['prev_neighbours'].append(prev_idx)\n",
    "                        if idx_graph_representation not in graph[prev_idx]['next_neighbours'] and idx_graph_representation != prev_idx:\n",
    "                            graph[prev_idx]['next_neighbours'].append(idx_graph_representation)\n",
    "                    prev_idx = idx_graph_representation\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_frequencies_list_reduce(tweets, treshold=2):\n",
    "    words, freqs = word_frequencies_list(tweets)\n",
    "    new_words, new_freqs = reduce_word_list(words, freqs, treshold)\n",
    "    graph = []\n",
    "    graph_idx = 0\n",
    "    for tweet in tweets:\n",
    "        words_in_sentence = tweet.split(' ')\n",
    "        prev_idx = -1\n",
    "        idx_now = 0\n",
    "        for word in words_in_sentence:\n",
    "            if word != '' and word in new_words:\n",
    "                is_not_in_graph = True\n",
    "                for idx_graph in range(len(graph)):\n",
    "                    if graph[idx_graph]['word'] == word:\n",
    "                        graph[idx_graph]['counter'] += 1\n",
    "                        is_not_in_graph = False\n",
    "                        idx_graph_representation = idx_graph\n",
    "                        break\n",
    "                if is_not_in_graph:\n",
    "                    node = {\n",
    "                        'idx': graph_idx,\n",
    "                        'word': word,\n",
    "                        'counter': 1,\n",
    "                        'next_neighbours': [],\n",
    "                        'prev_neighbours': []\n",
    "                    }\n",
    "                    if prev_idx != -1:\n",
    "                        node['prev_neighbours'].append(prev_idx)\n",
    "                        if graph_idx not in graph[prev_idx]['next_neighbours'] and graph_idx != prev_idx:\n",
    "                            graph[prev_idx]['next_neighbours'].append(graph_idx)\n",
    "                    prev_idx = graph_idx\n",
    "                    graph_idx += 1\n",
    "                    graph.append(node)\n",
    "                else:\n",
    "                    if prev_idx != -1:\n",
    "                        if prev_idx not in graph[idx_graph_representation]['prev_neighbours'] and idx_graph_representation != prev_idx:\n",
    "                            graph[idx_graph_representation]['prev_neighbours'].append(prev_idx)\n",
    "                        if idx_graph_representation not in graph[prev_idx]['next_neighbours'] and idx_graph_representation != prev_idx:\n",
    "                            graph[prev_idx]['next_neighbours'].append(idx_graph_representation)\n",
    "                    prev_idx = idx_graph_representation\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_weight(counter, distance, base):\n",
    "    if distance == 0:\n",
    "        return counter - (distance * (math.log(counter)/math.log(base)))\n",
    "    return (counter - (distance * (math.log(counter)/math.log(base)))) / distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_path(idx, graph, distance, base, data={'path': [], 'weight': 0}, iterator=5):\n",
    "    if len(graph[idx]['next_neighbours']) == 0 or iterator == distance:\n",
    "        new_data = {\n",
    "            'path': data['path'].copy(),\n",
    "            'weight': data['weight']\n",
    "        }\n",
    "        if idx not in data['path']:\n",
    "            new_data['path'].append(idx)\n",
    "            new_data['weight'] += calculate_weight(graph[idx]['counter'], distance, base)\n",
    "        return new_data\n",
    "    else:\n",
    "        new_data = {\n",
    "            'path': data['path'].copy(),\n",
    "            'weight': data['weight']\n",
    "        }\n",
    "        if idx not in data['path']:\n",
    "            new_data['path'].append(idx)\n",
    "            new_data['weight'] += calculate_weight(graph[idx]['counter'], distance, base)\n",
    "            neighbours = []\n",
    "            for next_idx in graph[idx]['next_neighbours']:\n",
    "                data_send = {\n",
    "                    'path': new_data['path'].copy(),\n",
    "                    'weight': data['weight']\n",
    "                }\n",
    "                if next_idx not in data_send['path']:\n",
    "                    neighbours.append(get_next_path(next_idx, graph, distance + 1, base, data_send, iterator))\n",
    "            data_max = {'path': [], 'weight': 0}\n",
    "            for neighbour in neighbours:\n",
    "                if neighbour['weight'] > data_max['weight']:\n",
    "                    data_max = neighbour.copy()\n",
    "            return data_max.copy()\n",
    "        else:\n",
    "            return new_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_path(idx, graph, distance, base, data={'path': [], 'weight': 0}, iterator=7):\n",
    "    if len(graph[idx]['next_neighbours']) == 0 or iterator == distance:\n",
    "        new_data = {\n",
    "            'path': data['path'].copy(),\n",
    "            'weight': data['weight']\n",
    "        }\n",
    "        if idx not in data['path']:\n",
    "            new_data['path'].insert(0, idx)\n",
    "            new_data['weight'] += calculate_weight(graph[idx]['counter'], distance, base)\n",
    "        return new_data\n",
    "    else:\n",
    "        new_data = {\n",
    "            'path': data['path'].copy(),\n",
    "            'weight': data['weight']\n",
    "        }\n",
    "        if idx not in data['path']:\n",
    "            new_data['path'].insert(0, idx)\n",
    "            new_data['weight'] += calculate_weight(graph[idx]['counter'], distance, base)\n",
    "            neighbours = []\n",
    "            for next_idx in graph[idx]['prev_neighbours']:\n",
    "                data_send = {\n",
    "                    'path': new_data['path'].copy(),\n",
    "                    'weight': data['weight']\n",
    "                }\n",
    "                if next_idx not in data_send['path']:\n",
    "                    neighbours.append(get_prev_path(next_idx, graph, distance + 1, base, data_send, iterator))\n",
    "            data_max = {'path': [], 'weight': 0}\n",
    "            for neighbour in neighbours:\n",
    "                if neighbour['weight'] > data_max['weight']:\n",
    "                    data_max = neighbour.copy()\n",
    "            return data_max.copy()\n",
    "        else:\n",
    "            return new_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_index(graph, topic):\n",
    "    for node in graph:\n",
    "        if node['word'] == topic:\n",
    "            return node['idx']\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_path(path_next, path_prev):\n",
    "    all_path = {\n",
    "        'path': path_prev['path'][:-1] + path_next['path'],\n",
    "        'weight': path_prev['weight'] + path_next['weight']\n",
    "    }\n",
    "    return all_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(graph, path):\n",
    "    sentence = ''\n",
    "    for item in path['path']:\n",
    "        for node in graph:\n",
    "            if node['idx'] == item:\n",
    "                sentence += node['word'] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(tweets, topic, base=2, iterator=5, treshold=10):\n",
    "    graph = graph_frequencies_list_reduce(tweets, treshold)\n",
    "    topic_index = get_topic_index(graph, topic)\n",
    "    if topic_index == -1:\n",
    "        return 'this string cannot be a topic'\n",
    "    path_next = get_next_path(topic_index, graph, 0, base, iterator=iterator)\n",
    "    path_prev = get_prev_path(topic_index, graph, 0, base, iterator=iterator)\n",
    "    all_path = combine_path(path_next, path_prev)\n",
    "    return get_sentence(graph, all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trendinc_topic = df_tweets_train['trending_topic'].iloc[0].replace('#', '').lower()\n",
    "sentence = summarize(df_tweets_train['tweet'], trendinc_topic, treshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angklung salah waris budaya mancanegara pesonaangklungfestival masyarakat kehususnya kabupaten kuningan angklung \n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_dict(sentence, tweet):\n",
    "    list_of_word_sentence = sentence.split(' ')\n",
    "    list_of_word_tweet = tweet.split(' ')\n",
    "    list_word = set(list_of_word_sentence) | set(list_of_word_tweet)\n",
    "    data = []\n",
    "    dict_sentence = {}\n",
    "    dict_tweet = {}\n",
    "    for word in list_word:\n",
    "        if word not in dict_sentence:\n",
    "            dict_sentence[word] = 0\n",
    "        if word not in dict_tweet:\n",
    "            dict_tweet[word] = 0\n",
    "    for word in list_of_word_sentence:\n",
    "        dict_sentence[word] += 1\n",
    "    for word in list_of_word_tweet:\n",
    "        dict_tweet[word] += 1\n",
    "    data.append(dict_sentence)\n",
    "    data.append(dict_tweet)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_array(sentence, tweet):\n",
    "    list_of_word_sentence = sentence.split(' ')\n",
    "    list_of_word_tweet = tweet.split(' ')\n",
    "    list_word = set(list_of_word_sentence) | set(list_of_word_tweet)\n",
    "    dict_sentence = []\n",
    "    dict_tweet = []\n",
    "    for word in list_word:\n",
    "        dict_sentence.append(list_of_word_sentence.count(word))\n",
    "        dict_tweet.append(list_of_word_tweet.count(word))\n",
    "    return [dict_sentence, dict_tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def normalize_bag_of_words(vector_word):\n",
    "    norm_vector_word = []\n",
    "    norm_sentence = norm(vector_word[0])\n",
    "    norm_tweet = norm(vector_word[1])\n",
    "    dict_sentence = [value * norm_sentence / len(vector_word[0]) for value in vector_word[0]]\n",
    "    dict_tweet = [value * norm_tweet / len(vector_word[1]) for value in vector_word[1]]\n",
    "    return [dict_sentence, dict_tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_similarity(vector_word):\n",
    "    sum = 0\n",
    "    for idx in range(len(vector_word[0])):\n",
    "        sum += (vector_word[0][idx] * vector_word[1][idx])\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(sentence, tweets):\n",
    "    data = []\n",
    "    for tweet in tweets:\n",
    "        data.append(count_similarity(normalize_bag_of_words(bag_of_words_array(sentence, tweet))))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['similarity'] = get_similarity(sentence, df_tweets_train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-285b8a417d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'similarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'similarity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2007\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "df_tweets['tweet'][df_tweets['similarity'] == max(df_tweets['similarity'])].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angklung salah waris budaya mancanegara pesonaangklungfestival masyarakat kehususnya kabupaten kuningan angklung \n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_frequencies_list_reduce(df_tweets_train['tweet'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = pd.DataFrame(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>idx</th>\n",
       "      <th>next_neighbours</th>\n",
       "      <th>prev_neighbours</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 48, 5, 77, 116, 118, 50, 152, 26, 49, 15, ...</td>\n",
       "      <td>[70, 11, 125, 49, 78, 151, 5, 116, 100, 113, 6...</td>\n",
       "      <td>event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1827</td>\n",
       "      <td>1</td>\n",
       "      <td>[2, 9, 20, 40, 44, 49, 52, 58, 61, 32, 63, 84,...</td>\n",
       "      <td>[0, 8, 39, 43, 48, 51, 21, 32, 66, 50, 23, 16,...</td>\n",
       "      <td>angklung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>sanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>533</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 19, 43, 81, 107, 133, 2]</td>\n",
       "      <td>[2, 52, 59, 80, 79, 1, 132, 63, 119, 4]</td>\n",
       "      <td>budaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 63, 121, 3]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>mancanegara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2512</td>\n",
       "      <td>5</td>\n",
       "      <td>[24, 29, 89, 114, 32, 122, 57, 38, 1, 108, 117...</td>\n",
       "      <td>[4, 14, 19, 11, 23, 34, 44, 47, 56, 60, 68, 0,...</td>\n",
       "      <td>pesonaangklungfestival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193</td>\n",
       "      <td>6</td>\n",
       "      <td>[7, 120, 132, 5, 48, 1, 32]</td>\n",
       "      <td>[119, 60, 141, 5, 0, 32]</td>\n",
       "      <td>tarik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[6, 119]</td>\n",
       "      <td>indah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>alun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>tani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[9, 1]</td>\n",
       "      <td>musisi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>329</td>\n",
       "      <td>11</td>\n",
       "      <td>[12, 5, 20, 0, 23, 29, 118]</td>\n",
       "      <td>[10, 22, 29, 58]</td>\n",
       "      <td>sunda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>141</td>\n",
       "      <td>12</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[11, 9]</td>\n",
       "      <td>rita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>141</td>\n",
       "      <td>13</td>\n",
       "      <td>[14, 59]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>tila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>[5, 1, 143]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>nyanyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>334</td>\n",
       "      <td>15</td>\n",
       "      <td>[16, 73, 74]</td>\n",
       "      <td>[72, 77, 1, 17, 78, 125, 0, 99, 116]</td>\n",
       "      <td>gedung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>130</td>\n",
       "      <td>16</td>\n",
       "      <td>[17, 1, 32]</td>\n",
       "      <td>[15, 97, 5]</td>\n",
       "      <td>jalan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>266</td>\n",
       "      <td>17</td>\n",
       "      <td>[18, 46, 5, 15, 99]</td>\n",
       "      <td>[16, 76, 109, 112]</td>\n",
       "      <td>sejarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>66</td>\n",
       "      <td>18</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>merdeka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>544</td>\n",
       "      <td>19</td>\n",
       "      <td>[5, 52, 53, 33, 121, 78, 35, 40, 71, 1, 20, 12...</td>\n",
       "      <td>[18, 42, 3, 43, 107, 21, 78, 47]</td>\n",
       "      <td>indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>273</td>\n",
       "      <td>20</td>\n",
       "      <td>[21, 43]</td>\n",
       "      <td>[1, 11, 95, 122, 63, 19, 66]</td>\n",
       "      <td>alat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>341</td>\n",
       "      <td>21</td>\n",
       "      <td>[22, 43, 1, 96, 23, 129, 19, 107, 5]</td>\n",
       "      <td>[20, 57]</td>\n",
       "      <td>musik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>nomor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>78</td>\n",
       "      <td>23</td>\n",
       "      <td>[5, 1, 62]</td>\n",
       "      <td>[83, 21, 11, 1]</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>101</td>\n",
       "      <td>24</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>61</td>\n",
       "      <td>25</td>\n",
       "      <td>[26, 5]</td>\n",
       "      <td>[47, 5]</td>\n",
       "      <td>harap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[25, 0]</td>\n",
       "      <td>tumbuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>61</td>\n",
       "      <td>27</td>\n",
       "      <td>[28, 5]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>semangat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>28</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[27]</td>\n",
       "      <td>nasionalisme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>328</td>\n",
       "      <td>29</td>\n",
       "      <td>[30, 11, 32, 95, 5, 31]</td>\n",
       "      <td>[28, 5, 45, 1, 140, 127, 49, 66, 80, 76, 11]</td>\n",
       "      <td>masyarakat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>68</td>\n",
       "      <td>123</td>\n",
       "      <td>[124]</td>\n",
       "      <td>[37, 56, 19, 82, 120]</td>\n",
       "      <td>arief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>68</td>\n",
       "      <td>124</td>\n",
       "      <td>[70, 125, 5]</td>\n",
       "      <td>[123]</td>\n",
       "      <td>yahya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>120</td>\n",
       "      <td>125</td>\n",
       "      <td>[0, 142, 15, 78]</td>\n",
       "      <td>[70, 124, 113, 121, 5, 0]</td>\n",
       "      <td>laksana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>62</td>\n",
       "      <td>126</td>\n",
       "      <td>[127]</td>\n",
       "      <td>[56, 5]</td>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>63</td>\n",
       "      <td>127</td>\n",
       "      <td>[82, 29]</td>\n",
       "      <td>[126]</td>\n",
       "      <td>hadir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>58</td>\n",
       "      <td>128</td>\n",
       "      <td>[5, 38, 78]</td>\n",
       "      <td>[121, 49]</td>\n",
       "      <td>kamis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>70</td>\n",
       "      <td>129</td>\n",
       "      <td>[130, 5]</td>\n",
       "      <td>[21, 1]</td>\n",
       "      <td>buat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>68</td>\n",
       "      <td>130</td>\n",
       "      <td>[63, 5]</td>\n",
       "      <td>[129]</td>\n",
       "      <td>bambu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>67</td>\n",
       "      <td>131</td>\n",
       "      <td>[63, 52]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>tetap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>126</td>\n",
       "      <td>132</td>\n",
       "      <td>[3, 59, 1]</td>\n",
       "      <td>[6, 1, 0]</td>\n",
       "      <td>padu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>64</td>\n",
       "      <td>133</td>\n",
       "      <td>[121, 5]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>negara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>57</td>\n",
       "      <td>134</td>\n",
       "      <td>[135]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>kabid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>116</td>\n",
       "      <td>135</td>\n",
       "      <td>[136, 146]</td>\n",
       "      <td>[134, 61]</td>\n",
       "      <td>pasar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>57</td>\n",
       "      <td>136</td>\n",
       "      <td>[36, 34]</td>\n",
       "      <td>[135]</td>\n",
       "      <td>area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>57</td>\n",
       "      <td>137</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>gunawan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>60</td>\n",
       "      <td>138</td>\n",
       "      <td>[98]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>cipta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>60</td>\n",
       "      <td>139</td>\n",
       "      <td>[140]</td>\n",
       "      <td>[98]</td>\n",
       "      <td>pandang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>60</td>\n",
       "      <td>140</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[139]</td>\n",
       "      <td>hidup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>59</td>\n",
       "      <td>141</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>[60, 5]</td>\n",
       "      <td>saji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>56</td>\n",
       "      <td>142</td>\n",
       "      <td>[143]</td>\n",
       "      <td>[125]</td>\n",
       "      <td>tugas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>59</td>\n",
       "      <td>143</td>\n",
       "      <td>[144]</td>\n",
       "      <td>[142, 14]</td>\n",
       "      <td>pelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>59</td>\n",
       "      <td>144</td>\n",
       "      <td>[145]</td>\n",
       "      <td>[143]</td>\n",
       "      <td>deputi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>[61, 5]</td>\n",
       "      <td>[144]</td>\n",
       "      <td>bidang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>70</td>\n",
       "      <td>146</td>\n",
       "      <td>[147, 1, 5]</td>\n",
       "      <td>[135, 121, 82]</td>\n",
       "      <td>ni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>69</td>\n",
       "      <td>147</td>\n",
       "      <td>[148, 5]</td>\n",
       "      <td>[146]</td>\n",
       "      <td>wayan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>62</td>\n",
       "      <td>148</td>\n",
       "      <td>[149, 5]</td>\n",
       "      <td>[147, 121]</td>\n",
       "      <td>giri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>61</td>\n",
       "      <td>149</td>\n",
       "      <td>[63, 5, 150, 151]</td>\n",
       "      <td>[148]</td>\n",
       "      <td>adnyani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>62</td>\n",
       "      <td>150</td>\n",
       "      <td>[151]</td>\n",
       "      <td>[63, 149]</td>\n",
       "      <td>atraksi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>69</td>\n",
       "      <td>151</td>\n",
       "      <td>[0, 49, 83, 5, 152]</td>\n",
       "      <td>[150, 5, 149]</td>\n",
       "      <td>tunggu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>71</td>\n",
       "      <td>152</td>\n",
       "      <td>[5, 59, 57, 58, 121, 119]</td>\n",
       "      <td>[0, 1, 49, 151]</td>\n",
       "      <td>kolaborasi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     counter  idx                                    next_neighbours  \\\n",
       "0        468    0  [1, 48, 5, 77, 116, 118, 50, 152, 26, 49, 15, ...   \n",
       "1       1827    1  [2, 9, 20, 40, 44, 49, 52, 58, 61, 32, 63, 84,...   \n",
       "2         70    2                                             [3, 1]   \n",
       "3        533    3                       [4, 19, 43, 81, 107, 133, 2]   \n",
       "4         68    4                                    [5, 63, 121, 3]   \n",
       "5       2512    5  [24, 29, 89, 114, 32, 122, 57, 38, 1, 108, 117...   \n",
       "6        193    6                        [7, 120, 132, 5, 48, 1, 32]   \n",
       "7         67    7                                                [8]   \n",
       "8         68    8                                                [1]   \n",
       "9         68    9                                           [10, 12]   \n",
       "10        67   10                                               [11]   \n",
       "11       329   11                        [12, 5, 20, 0, 23, 29, 118]   \n",
       "12       141   12                                               [13]   \n",
       "13       141   13                                           [14, 59]   \n",
       "14        69   14                                        [5, 1, 143]   \n",
       "15       334   15                                       [16, 73, 74]   \n",
       "16       130   16                                        [17, 1, 32]   \n",
       "17       266   17                                [18, 46, 5, 15, 99]   \n",
       "18        66   18                                               [19]   \n",
       "19       544   19  [5, 52, 53, 33, 121, 78, 35, 40, 71, 1, 20, 12...   \n",
       "20       273   20                                           [21, 43]   \n",
       "21       341   21               [22, 43, 1, 96, 23, 129, 19, 107, 5]   \n",
       "22        58   22                                               [11]   \n",
       "23        78   23                                         [5, 1, 62]   \n",
       "24       101   24                                                 []   \n",
       "25        61   25                                            [26, 5]   \n",
       "26        60   26                                               [27]   \n",
       "27        61   27                                            [28, 5]   \n",
       "28        60   28                                               [29]   \n",
       "29       328   29                            [30, 11, 32, 95, 5, 31]   \n",
       "..       ...  ...                                                ...   \n",
       "123       68  123                                              [124]   \n",
       "124       68  124                                       [70, 125, 5]   \n",
       "125      120  125                                   [0, 142, 15, 78]   \n",
       "126       62  126                                              [127]   \n",
       "127       63  127                                           [82, 29]   \n",
       "128       58  128                                        [5, 38, 78]   \n",
       "129       70  129                                           [130, 5]   \n",
       "130       68  130                                            [63, 5]   \n",
       "131       67  131                                           [63, 52]   \n",
       "132      126  132                                         [3, 59, 1]   \n",
       "133       64  133                                           [121, 5]   \n",
       "134       57  134                                              [135]   \n",
       "135      116  135                                         [136, 146]   \n",
       "136       57  136                                           [36, 34]   \n",
       "137       57  137                                                [1]   \n",
       "138       60  138                                               [98]   \n",
       "139       60  139                                              [140]   \n",
       "140       60  140                                               [29]   \n",
       "141       59  141                                             [5, 6]   \n",
       "142       56  142                                              [143]   \n",
       "143       59  143                                              [144]   \n",
       "144       59  144                                              [145]   \n",
       "145       59  145                                            [61, 5]   \n",
       "146       70  146                                        [147, 1, 5]   \n",
       "147       69  147                                           [148, 5]   \n",
       "148       62  148                                           [149, 5]   \n",
       "149       61  149                                  [63, 5, 150, 151]   \n",
       "150       62  150                                              [151]   \n",
       "151       69  151                                [0, 49, 83, 5, 152]   \n",
       "152       71  152                          [5, 59, 57, 58, 121, 119]   \n",
       "\n",
       "                                       prev_neighbours                    word  \n",
       "0    [70, 11, 125, 49, 78, 151, 5, 116, 100, 113, 6...                   event  \n",
       "1    [0, 8, 39, 43, 48, 51, 21, 32, 66, 50, 23, 16,...                angklung  \n",
       "2                                               [1, 3]                 sanding  \n",
       "3              [2, 52, 59, 80, 79, 1, 132, 63, 119, 4]                  budaya  \n",
       "4                                                  [3]             mancanegara  \n",
       "5    [4, 14, 19, 11, 23, 34, 44, 47, 56, 60, 68, 0,...  pesonaangklungfestival  \n",
       "6                             [119, 60, 141, 5, 0, 32]                   tarik  \n",
       "7                                             [6, 119]                   indah  \n",
       "8                                                  [7]                    alun  \n",
       "9                                                  [1]                    tani  \n",
       "10                                              [9, 1]                  musisi  \n",
       "11                                    [10, 22, 29, 58]                   sunda  \n",
       "12                                             [11, 9]                    rita  \n",
       "13                                                [12]                    tila  \n",
       "14                                                [13]                  nyanyi  \n",
       "15                [72, 77, 1, 17, 78, 125, 0, 99, 116]                  gedung  \n",
       "16                                         [15, 97, 5]                   jalan  \n",
       "17                                  [16, 76, 109, 112]                 sejarah  \n",
       "18                                                [17]                 merdeka  \n",
       "19                    [18, 42, 3, 43, 107, 21, 78, 47]               indonesia  \n",
       "20                        [1, 11, 95, 122, 63, 19, 66]                    alat  \n",
       "21                                            [20, 57]                   musik  \n",
       "22                                                [21]                   nomor  \n",
       "23                                     [83, 21, 11, 1]                    main  \n",
       "24                                                 [5]                  status  \n",
       "25                                             [47, 5]                   harap  \n",
       "26                                             [25, 0]                  tumbuh  \n",
       "27                                                [26]                semangat  \n",
       "28                                                [27]            nasionalisme  \n",
       "29        [28, 5, 45, 1, 140, 127, 49, 66, 80, 76, 11]              masyarakat  \n",
       "..                                                 ...                     ...  \n",
       "123                              [37, 56, 19, 82, 120]                   arief  \n",
       "124                                              [123]                   yahya  \n",
       "125                          [70, 124, 113, 121, 5, 0]                 laksana  \n",
       "126                                            [56, 5]                   value  \n",
       "127                                              [126]                   hadir  \n",
       "128                                          [121, 49]                   kamis  \n",
       "129                                            [21, 1]                    buat  \n",
       "130                                              [129]                   bambu  \n",
       "131                                                [1]                   tetap  \n",
       "132                                          [6, 1, 0]                    padu  \n",
       "133                                                [3]                  negara  \n",
       "134                                                [5]                   kabid  \n",
       "135                                          [134, 61]                   pasar  \n",
       "136                                              [135]                    area  \n",
       "137                                               [34]                 gunawan  \n",
       "138                                                [1]                   cipta  \n",
       "139                                               [98]                 pandang  \n",
       "140                                              [139]                   hidup  \n",
       "141                                            [60, 5]                    saji  \n",
       "142                                              [125]                   tugas  \n",
       "143                                          [142, 14]                    pelt  \n",
       "144                                              [143]                  deputi  \n",
       "145                                              [144]                  bidang  \n",
       "146                                     [135, 121, 82]                      ni  \n",
       "147                                              [146]                   wayan  \n",
       "148                                         [147, 121]                    giri  \n",
       "149                                              [148]                 adnyani  \n",
       "150                                          [63, 149]                 atraksi  \n",
       "151                                      [150, 5, 149]                  tunggu  \n",
       "152                                    [0, 1, 49, 151]              kolaborasi  \n",
       "\n",
       "[153 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
